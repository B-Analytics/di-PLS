

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>diPLSlib package &mdash; diPLSlib 2.4.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=4d935f96"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="diPLSlib.utils subpackage" href="diPLSlib.utils.html" />
    <link rel="prev" title="diPLSlib documentation" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            diPLSlib
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">diPLSlib package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-diPLSlib.functions">diPLSlib.functions module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#diPLSlib.functions.convex_relaxation"><code class="docutils literal notranslate"><span class="pre">convex_relaxation()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#diPLSlib.functions.dipals"><code class="docutils literal notranslate"><span class="pre">dipals()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#diPLSlib.functions.edpls"><code class="docutils literal notranslate"><span class="pre">edpls()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#diPLSlib.functions.transfer_laplacian"><code class="docutils literal notranslate"><span class="pre">transfer_laplacian()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-diPLSlib.models">diPLSlib.models module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#diPLSlib.models.DIPLS"><code class="docutils literal notranslate"><span class="pre">DIPLS</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#diPLSlib.models.DIPLS.fit"><code class="docutils literal notranslate"><span class="pre">DIPLS.fit()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#diPLSlib.models.DIPLS.predict"><code class="docutils literal notranslate"><span class="pre">DIPLS.predict()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#diPLSlib.models.DIPLS.set_fit_request"><code class="docutils literal notranslate"><span class="pre">DIPLS.set_fit_request()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#diPLSlib.models.DIPLS.set_score_request"><code class="docutils literal notranslate"><span class="pre">DIPLS.set_score_request()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#diPLSlib.models.EDPLS"><code class="docutils literal notranslate"><span class="pre">EDPLS</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#diPLSlib.models.EDPLS.fit"><code class="docutils literal notranslate"><span class="pre">EDPLS.fit()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#diPLSlib.models.EDPLS.predict"><code class="docutils literal notranslate"><span class="pre">EDPLS.predict()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#diPLSlib.models.EDPLS.set_predict_request"><code class="docutils literal notranslate"><span class="pre">EDPLS.set_predict_request()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#diPLSlib.models.EDPLS.set_score_request"><code class="docutils literal notranslate"><span class="pre">EDPLS.set_score_request()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#diPLSlib.models.GCTPLS"><code class="docutils literal notranslate"><span class="pre">GCTPLS</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#diPLSlib.models.GCTPLS.fit"><code class="docutils literal notranslate"><span class="pre">GCTPLS.fit()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#diPLSlib.models.GCTPLS.set_fit_request"><code class="docutils literal notranslate"><span class="pre">GCTPLS.set_fit_request()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#diPLSlib.models.GCTPLS.set_score_request"><code class="docutils literal notranslate"><span class="pre">GCTPLS.set_score_request()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#diplslib-utils-subpackage">diPLSlib.utils subpackage</a><ul>
<li class="toctree-l3"><a class="reference internal" href="diPLSlib.utils.html">diPLSlib.utils subpackage</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-diPLSlib">Module contents</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">diPLSlib</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">diPLSlib package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/diPLSlib.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="diplslib-package">
<h1>diPLSlib package<a class="headerlink" href="#diplslib-package" title="Link to this heading"></a></h1>
<section id="module-diPLSlib.functions">
<span id="diplslib-functions-module"></span><h2>diPLSlib.functions module<a class="headerlink" href="#module-diPLSlib.functions" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="diPLSlib.functions.convex_relaxation">
<span class="sig-prename descclassname"><span class="pre">diPLSlib.functions.</span></span><span class="sig-name descname"><span class="pre">convex_relaxation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">xs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xt</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/diPLSlib/functions.html#convex_relaxation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#diPLSlib.functions.convex_relaxation" title="Link to this definition"></a></dt>
<dd><p>Perform convex relaxation of the covariance difference matrix.</p>
<p>This relaxation involves computing the eigenvalue decomposition of the symmetric covariance 
difference matrix, inverting the signs of negative eigenvalues, and reconstructing the matrix.
This corresponds to an upper bound on the covariance difference between source and target domains.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>xs</strong><span class="classifier">ndarray of shape (n_source_samples, n_features)</span></dt><dd><p>Feature data from the source domain.</p>
</dd>
<dt><strong>xt</strong><span class="classifier">ndarray of shape (n_target_samples, n_features)</span></dt><dd><p>Feature data from the target domain.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>D</strong><span class="classifier">ndarray of shape (n_features, n_features)</span></dt><dd><p>Relaxed covariance difference matrix.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<p>Ramin Nikzad-Langerodi et al., “Domain-Invariant Regression under Beer-Lambert’s Law”, Proc. ICMLA, 2019.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">diPLSlib.functions</span> <span class="kn">import</span> <span class="n">convex_relaxation</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">D</span> <span class="o">=</span> <span class="n">convex_relaxation</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="diPLSlib.functions.dipals">
<span class="sig-prename descclassname"><span class="pre">diPLSlib.functions.</span></span><span class="sig-name descname"><span class="pre">dipals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">heuristic</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_domain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">laplacian</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/diPLSlib/functions.html#dipals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#diPLSlib.functions.dipals" title="Link to this definition"></a></dt>
<dd><p>Perform (Multiple) Domain-Invariant Partial Least Squares (di-PLS) regression.</p>
<p>This method fits a PLS regression model using labeled source domain data and potentially 
unlabeled target domain data across multiple domains, aiming to build a model that 
generalizes well across different domains.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">ndarray of shape (n_samples, n_features)</span></dt><dd><p>Labeled source domain data.</p>
</dd>
<dt><strong>y</strong><span class="classifier">ndarray of shape (n_samples, 1)</span></dt><dd><p>Response variable associated with the source domain.</p>
</dd>
<dt><strong>xs</strong><span class="classifier">ndarray of shape (n_source_samples, n_features)</span></dt><dd><p>Source domain feature data.</p>
</dd>
<dt><strong>xt</strong><span class="classifier">ndarray of shape (n_target_samples, n_features) or list of ndarray</span></dt><dd><p>Target domain feature data. Multiple domains can be provided as a list.</p>
</dd>
<dt><strong>A</strong><span class="classifier">int</span></dt><dd><p>Number of latent variables to use in the model.</p>
</dd>
<dt><strong>l</strong><span class="classifier">float or tuple of len(l)=A</span></dt><dd><p>Regularization parameter. If a single value is provided, the same regularization is applied to all latent variables.</p>
</dd>
<dt><strong>heuristic</strong><span class="classifier">bool, default=False</span></dt><dd><p>If True, automatically determine the regularization parameter to equally balance fitting 
to Y and minimizing domain discrepancy.</p>
</dd>
<dt><strong>target_domain</strong><span class="classifier">int, default=0</span></dt><dd><p>Specifies which target domain the model should apply to, where 0 indicates the source domain.</p>
</dd>
<dt><strong>laplacian</strong><span class="classifier">bool, default=False</span></dt><dd><p>If True, uses a Laplacian matrix to regularize distances between matched calibration transfer 
samples in latent variable space.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>b</strong><span class="classifier">ndarray of shape (n_features, 1)</span></dt><dd><p>Regression coefficient vector.</p>
</dd>
<dt><strong>b0</strong><span class="classifier">float</span></dt><dd><p>Intercept of the regression model.</p>
</dd>
<dt><strong>T</strong><span class="classifier">ndarray of shape (n_samples, A)</span></dt><dd><p>Training data projections (scores).</p>
</dd>
<dt><strong>Ts</strong><span class="classifier">ndarray of shape (n_source_samples, A)</span></dt><dd><p>Source domain projections (scores).</p>
</dd>
<dt><strong>Tt</strong><span class="classifier">ndarray of shape (n_target_samples, A)</span></dt><dd><p>Target domain projections (scores).</p>
</dd>
<dt><strong>W</strong><span class="classifier">ndarray of shape (n_features, A)</span></dt><dd><p>Weight matrix.</p>
</dd>
<dt><strong>P</strong><span class="classifier">ndarray of shape (n_features, A)</span></dt><dd><p>Loadings matrix corresponding to x.</p>
</dd>
<dt><strong>Ps</strong><span class="classifier">ndarray of shape (n_features, A)</span></dt><dd><p>Loadings matrix corresponding to xs.</p>
</dd>
<dt><strong>Pt</strong><span class="classifier">ndarray of shape (n_features, A)</span></dt><dd><p>Loadings matrix corresponding to xt.</p>
</dd>
<dt><strong>E</strong><span class="classifier">ndarray of shape (n_source_samples, n_features)</span></dt><dd><p>Residuals of source domain data.</p>
</dd>
<dt><strong>Es</strong><span class="classifier">ndarray of shape (n_source_samples, n_features)</span></dt><dd><p>Source domain residual matrix.</p>
</dd>
<dt><strong>Et</strong><span class="classifier">ndarray of shape (n_target_samples, n_features)</span></dt><dd><p>Target domain residual matrix.</p>
</dd>
<dt><strong>Ey</strong><span class="classifier">ndarray of shape (n_source_samples, 1)</span></dt><dd><p>Residuals of response variable in the source domain.</p>
</dd>
<dt><strong>C</strong><span class="classifier">ndarray of shape (A, 1)</span></dt><dd><p>Regression vector relating source projections to the response variable.</p>
</dd>
<dt><strong>opt_l</strong><span class="classifier">ndarray of shape (A, 1)</span></dt><dd><p>Heuristically determined regularization parameter for each latent variable.</p>
</dd>
<dt><strong>discrepancy</strong><span class="classifier">ndarray</span></dt><dd><p>The variance discrepancy between source and target domain projections.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<ol class="arabic simple">
<li><p>Ramin Nikzad-Langerodi et al., “Domain-Invariant Partial Least Squares Regression”, Analytical Chemistry, 2018.</p></li>
<li><p>Ramin Nikzad-Langerodi et al., “Domain-Invariant Regression under Beer-Lambert’s Law”, Proc. ICMLA, 2019.</p></li>
<li><p>Ramin Nikzad-Langerodi et al., Domain adaptation for regression under Beer–Lambert’s law, Knowledge-Based Systems, 2020.</p></li>
<li><ol class="upperalpha simple" start="2">
<li><p>Mikulasek et al., “Partial least squares regression with multiple domains”, Journal of Chemometrics, 2023.</p></li>
</ol>
</li>
</ol>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">diPLSlib.functions</span> <span class="kn">import</span> <span class="n">dipals</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">50</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">50</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">Ts</span><span class="p">,</span> <span class="n">Tt</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">Ps</span><span class="p">,</span> <span class="n">Pt</span><span class="p">,</span> <span class="n">E</span><span class="p">,</span> <span class="n">Es</span><span class="p">,</span> <span class="n">Et</span><span class="p">,</span> <span class="n">Ey</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">opt_l</span><span class="p">,</span> <span class="n">discrepancy</span> <span class="o">=</span> <span class="n">dipals</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="diPLSlib.functions.edpls">
<span class="sig-prename descclassname"><span class="pre">diPLSlib.functions.</span></span><span class="sig-name descname"><span class="pre">edpls</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_components</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.05</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/diPLSlib/functions.html#edpls"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#diPLSlib.functions.edpls" title="Link to this definition"></a></dt>
<dd><p><span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-Differentially Private Partial Least Squares Regression.</p>
<p>A Gaussian mechanism according to Balle &amp; Wang (2018) is used to privately release weights <span class="math notranslate nohighlight">\(\mathbf{W}\)</span>, scores <span class="math notranslate nohighlight">\(\mathbf{T}\)</span>
and <span class="math notranslate nohighlight">\(X/Y\)</span>-loadings <span class="math notranslate nohighlight">\(\mathbf{P}\)</span>/<span class="math notranslate nohighlight">\(\mathbf{c}\)</span> from the PLS1 algorithm. To this end, for each latent variable, i.i.d. noise from 
<span class="math notranslate nohighlight">\(\mathcal{N}(0,\sigma^2)\)</span> with variance satisfying</p>
<div class="math notranslate nohighlight">
\[\Phi\left( \frac{\Delta}{2\sigma} - \frac{\epsilon\sigma}{\Delta} \right) - e^{\epsilon} \Phi\left( -\frac{\Delta}{2\sigma} - \frac{\epsilon\sigma}{\Delta} \right)\leq \delta,\]</div>
<p>with <span class="math notranslate nohighlight">\(\Phi(t) = \mathrm P[\mathcal{N}(0,1)\leq t]\)</span> (i.e., the CDF of the standard univariate Gaussian distribution), is added to the weights, scores and loadings, whereas the sensitivity <span class="math notranslate nohighlight">\(\Delta(\cdot)\)</span> for the functions releasing the corresponding quantities is calculated as follows:</p>
<div class="math notranslate nohighlight">
\[\Delta(w) = \sup_{(\mathbf{x}, y)} |y| \|\mathbf{x}\|_2\]</div>
<div class="math notranslate nohighlight">
\[\Delta(t) \leq \sup_{\mathbf{x}}  \|\mathbf{x}\|_2\]</div>
<div class="math notranslate nohighlight">
\[\Delta(p) \leq \sup_{\mathbf{x}}  \|\mathbf{x}\|_2\]</div>
<div class="math notranslate nohighlight">
\[\Delta(c) \leq \sup_{y}  |y|.\]</div>
<p>Note that in contrast to the Gaussian mechanism, proposed in Dwork et al. (2006) and Dwork et al. (2014), the mechanism of Balle &amp; Wang (2018) guarantees <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy 
for any value of <span class="math notranslate nohighlight">\(\epsilon &gt; 0\)</span> and not only for <span class="math notranslate nohighlight">\(\epsilon \leq 1\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x: numpy array of shape (n, m)</strong></dt><dd><p>x-data</p>
</dd>
<dt><strong>y: numpy array of shape (n, p)</strong></dt><dd></dd>
<dt><strong>n_components: int</strong></dt><dd><p>Number of latent variables.</p>
</dd>
<dt><strong>epsilon: float</strong></dt><dd><p>Privacy loss parameter.</p>
</dd>
<dt><strong>delta: float, default=0.05</strong></dt><dd><p>Failure probability.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><a href="#id1"><span class="problematic" id="id2">coef_</span></a>: numpy array of shape (m,)</dt><dd><p>Regression coefficients.</p>
</dd>
<dt><a href="#id3"><span class="problematic" id="id4">x_scores_</span></a>: numpy array of shape (n, A)</dt><dd><p>X scores.</p>
</dd>
<dt><a href="#id5"><span class="problematic" id="id6">x_loadings_</span></a>: numpy array of shape (m, A)</dt><dd><p>X loadings.</p>
</dd>
<dt><a href="#id7"><span class="problematic" id="id8">x_weights_</span></a>: numpy array of shape (m, A)</dt><dd><p>X weights.</p>
</dd>
<dt><a href="#id9"><span class="problematic" id="id10">y_loadings_</span></a>: numpy array of shape (A, )</dt><dd><p>Y loadings.</p>
</dd>
<dt>x_residuals: numpy array of shape (n, m)</dt><dd><p>X residuals.</p>
</dd>
<dt>y_residuals: numpy array of shape (n, p)</dt><dd><p>Y residuals.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<ul class="simple">
<li><p>R.Nikzad-Langerodi, et al. (2024). (epsilon,delta)-Differentially private partial least squares regression (2024, unpublished).</p></li>
<li><p>Balle, B., &amp; Wang, Y. X. (2018, July). Improving the gaussian mechanism for differential privacy: Analytical calibration and optimal denoising. In International Conference on Machine Learning (pp. 394-403). PMLR.</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">diPLSlib.functions</span> <span class="kn">import</span> <span class="n">edpls</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">coef_</span><span class="p">,</span> <span class="n">x_weights_</span><span class="p">,</span> <span class="n">x_loadings_</span><span class="p">,</span> <span class="n">y_loadings_</span><span class="p">,</span> <span class="n">x_scores_</span><span class="p">,</span> <span class="n">x_residuals_</span><span class="p">,</span> <span class="n">y_residuals_</span> <span class="o">=</span> <span class="n">edpls</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="diPLSlib.functions.transfer_laplacian">
<span class="sig-prename descclassname"><span class="pre">diPLSlib.functions.</span></span><span class="sig-name descname"><span class="pre">transfer_laplacian</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="reference internal" href="_modules/diPLSlib/functions.html#transfer_laplacian"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#diPLSlib.functions.transfer_laplacian" title="Link to this definition"></a></dt>
<dd><p>Construct a Laplacian matrix for calibration transfer problems.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">ndarray of shape (n_samples, n_features)</span></dt><dd><p>Data samples from device 1.</p>
</dd>
<dt><strong>y</strong><span class="classifier">ndarray of shape (n_samples, n_features)</span></dt><dd><p>Data samples from device 2.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>L</strong><span class="classifier">ndarray of shape (2 * n_samples, 2 * n_samples)</span></dt><dd><p>The Laplacian matrix for the calibration transfer problem.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<p>Nikzad‐Langerodi, R., &amp; Sobieczky, F. (2021). Graph‐based calibration transfer. 
Journal of Chemometrics, 35(4), e3319.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">diPLSlib.functions</span> <span class="kn">import</span> <span class="n">transfer_laplacian</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">L</span> <span class="o">=</span> <span class="n">transfer_laplacian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
<span class="go">[[ 1.  0. -1. -0.]</span>
<span class="go"> [ 0.  1. -0. -1.]</span>
<span class="go"> [-1. -0.  1.  0.]</span>
<span class="go"> [-0. -1.  0.  1.]]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="module-diPLSlib.models">
<span id="diplslib-models-module"></span><h2>diPLSlib.models module<a class="headerlink" href="#module-diPLSlib.models" title="Link to this heading"></a></h2>
<p>diPLSlib model classes</p>
<ul class="simple">
<li><p>DIPLS base class</p></li>
<li><p>GCTPLS class</p></li>
</ul>
<dl class="py class">
<dt class="sig sig-object py" id="diPLSlib.models.DIPLS">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">diPLSlib.models.</span></span><span class="sig-name descname"><span class="pre">DIPLS</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">centering</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">heuristic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_domain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rescale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Target'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/diPLSlib/models.html#DIPLS"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#diPLSlib.models.DIPLS" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">RegressorMixin</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseEstimator</span></code></p>
<p>Domain-Invariant Partial Least Squares (DIPLS) algorithm for domain adaptation.</p>
<p>This class implements the DIPLS algorithm, which is designed to align feature distributions 
across different domains while predicting the target variable <cite>y</cite>. It supports multiple 
source and target domains through domain-specific feature transformations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>A</strong><span class="classifier">int</span></dt><dd><p>Number of latent variables to be used in the model.</p>
</dd>
<dt><strong>l</strong><span class="classifier">float or tuple with len(l)=A, default=0</span></dt><dd><p>Regularization parameter. If a single value is provided, the same regularization is applied to all latent variables.</p>
</dd>
<dt><strong>centering</strong><span class="classifier">bool, default=True</span></dt><dd><p>If True, source and target domain data are mean-centered.</p>
</dd>
<dt><strong>heuristic</strong><span class="classifier">bool, default=False</span></dt><dd><p>If True, the regularization parameter is set to a heuristic value that
balances fitting the output variable y and minimizing domain discrepancy.</p>
</dd>
<dt><strong>target_domain</strong><span class="classifier">int, default=0</span></dt><dd><p>If multiple target domains are passed, target_domain specifies
for which of the target domains the model should apply. 
If target_domain=0, the model applies to the source domain,
if target_domain=1, it applies to the first target domain, and so on.</p>
</dd>
<dt><strong>rescale</strong><span class="classifier">Union[str, ndarray], default=’Target’</span></dt><dd><p>Determines rescaling of the test data. If ‘Target’ or ‘Source’, the test data will be
rescaled to the mean of xt or xs, respectively. If an ndarray is provided, the test data
will be rescaled to the mean of the provided array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>n_</strong><span class="classifier">int</span></dt><dd><p>Number of samples in <cite>x</cite>.</p>
</dd>
<dt><strong>ns_</strong><span class="classifier">int</span></dt><dd><p>Number of samples in <cite>xs</cite>.</p>
</dd>
<dt><strong>nt_</strong><span class="classifier">int</span></dt><dd><p>Number of samples in <cite>xt</cite>.</p>
</dd>
<dt><strong>n_features_in_</strong><span class="classifier">int</span></dt><dd><p>Number of features (variables) in <cite>x</cite>.</p>
</dd>
<dt><strong>mu_</strong><span class="classifier">ndarray of shape (n_features,)</span></dt><dd><p>Mean of columns in <cite>x</cite>.</p>
</dd>
<dt><strong>mu_s_</strong><span class="classifier">ndarray of shape (n_features,)</span></dt><dd><p>Mean of columns in <cite>xs</cite>.</p>
</dd>
<dt><strong>mu_t_</strong><span class="classifier">ndarray of shape (n_features,) or ndarray of shape (n_domains, n_features)</span></dt><dd><p>Mean of columns in <cite>xt</cite>, averaged per target domain if multiple domains exist.</p>
</dd>
<dt><strong>b_</strong><span class="classifier">ndarray of shape (n_features, 1)</span></dt><dd><p>Regression coefficient vector.</p>
</dd>
<dt><strong>b0_</strong><span class="classifier">float</span></dt><dd><p>Intercept of the regression model.</p>
</dd>
<dt><strong>T_</strong><span class="classifier">ndarray of shape (n_samples, A)</span></dt><dd><p>Training data projections (scores).</p>
</dd>
<dt><strong>Ts_</strong><span class="classifier">ndarray of shape (n_source_samples, A)</span></dt><dd><p>Source domain projections (scores).</p>
</dd>
<dt><strong>Tt_</strong><span class="classifier">ndarray of shape (n_target_samples, A)</span></dt><dd><p>Target domain projections (scores).</p>
</dd>
<dt><strong>W_</strong><span class="classifier">ndarray of shape (n_features, A)</span></dt><dd><p>Weight matrix.</p>
</dd>
<dt><strong>P_</strong><span class="classifier">ndarray of shape (n_features, A)</span></dt><dd><p>Loadings matrix corresponding to x.</p>
</dd>
<dt><strong>Ps_</strong><span class="classifier">ndarray of shape (n_features, A)</span></dt><dd><p>Loadings matrix corresponding to xs.</p>
</dd>
<dt><strong>Pt_</strong><span class="classifier">ndarray of shape (n_features, A)</span></dt><dd><p>Loadings matrix corresponding to xt.</p>
</dd>
<dt><strong>E_</strong><span class="classifier">ndarray of shape (n_source_samples, n_features)</span></dt><dd><p>Residuals of source domain data.</p>
</dd>
<dt><strong>Es_</strong><span class="classifier">ndarray of shape (n_source_samples, n_features)</span></dt><dd><p>Source domain residual matrix.</p>
</dd>
<dt><strong>Et_</strong><span class="classifier">ndarray of shape (n_target_samples, n_features)</span></dt><dd><p>Target domain residual matrix.</p>
</dd>
<dt><strong>Ey_</strong><span class="classifier">ndarray of shape (n_source_samples, 1)</span></dt><dd><p>Residuals of response variable in the source domain.</p>
</dd>
<dt><strong>C_</strong><span class="classifier">ndarray of shape (A, 1)</span></dt><dd><p>Regression vector relating source projections to the response variable.</p>
</dd>
<dt><strong>opt_l_</strong><span class="classifier">ndarray of shape (A, 1)</span></dt><dd><p>Heuristically determined regularization parameter for each latent variable.</p>
</dd>
<dt><strong>discrepancy_</strong><span class="classifier">ndarray</span></dt><dd><p>The variance discrepancy between source and target domain projections.</p>
</dd>
<dt><strong>is_fitted_</strong><span class="classifier">bool, default=False</span></dt><dd><p>Whether the model has been fitted to data.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#diPLSlib.models.DIPLS.fit" title="diPLSlib.models.DIPLS.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(X, y[, xs, xt])</p></td>
<td><p>Fit the DIPLS model.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_metadata_routing</span></code>()</p></td>
<td><p>Get metadata routing of this object.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#diPLSlib.models.DIPLS.predict" title="diPLSlib.models.DIPLS.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(X)</p></td>
<td><p>Predict y using the fitted DIPLS model.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">score</span></code>(X, y[, sample_weight])</p></td>
<td><p>Return the coefficient of determination of the prediction.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#diPLSlib.models.DIPLS.set_fit_request" title="diPLSlib.models.DIPLS.set_fit_request"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_fit_request</span></code></a>(*[, xs, xt])</p></td>
<td><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#diPLSlib.models.DIPLS.set_score_request" title="diPLSlib.models.DIPLS.set_score_request"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_score_request</span></code></a>(*[, sample_weight])</p></td>
<td><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">score</span></code> method.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<ol class="arabic simple">
<li><p>Ramin Nikzad-Langerodi et al., “Domain-Invariant Partial Least Squares Regression”, Analytical Chemistry, 2018.</p></li>
<li><p>Ramin Nikzad-Langerodi et al., “Domain-Invariant Regression under Beer-Lambert’s Law”, Proc. ICMLA, 2019.</p></li>
<li><p>Ramin Nikzad-Langerodi et al., Domain adaptation for regression under Beer–Lambert’s law, Knowledge-Based Systems, 2020.</p></li>
<li><ol class="upperalpha simple" start="2">
<li><p>Mikulasek et al., “Partial least squares regression with multiple domains”, Journal of Chemometrics, 2023.</p></li>
</ol>
</li>
</ol>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">diPLSlib.models</span> <span class="kn">import</span> <span class="n">DIPLS</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">DIPLS</span><span class="p">(</span><span class="n">A</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">l</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span>
<span class="go">DIPLS(A=5, l=10)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xtest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">yhat</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xtest</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="diPLSlib.models.DIPLS.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/diPLSlib/models.html#DIPLS.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#diPLSlib.models.DIPLS.fit" title="Link to this definition"></a></dt>
<dd><p>Fit the DIPLS model.</p>
<p>This method fits the domain-invariant partial least squares (di-PLS) model
using the provided source and target domain data. It can handle both single 
and multiple target domains.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">ndarray of shape (n_samples, n_features)</span></dt><dd><p>Labeled input data from the source domain.</p>
</dd>
<dt><strong>y</strong><span class="classifier">ndarray of shape (n_samples, 1)</span></dt><dd><p>Response variable corresponding to the input data <cite>x</cite>.</p>
</dd>
<dt><strong>xs</strong><span class="classifier">ndarray of shape (n_samples_source, n_features)</span></dt><dd><p>Source domain X-data. If not provided, defaults to <cite>X</cite>.</p>
</dd>
<dt><strong>xt</strong><span class="classifier">Union[ndarray of shape (n_samples_target, n_features), List[ndarray]]</span></dt><dd><p>Target domain X-data. Can be a single target domain or a list of arrays 
representing multiple target domains. If not provided, defaults to <cite>X</cite>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>Fitted model instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="diPLSlib.models.DIPLS.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/diPLSlib/models.html#DIPLS.predict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#diPLSlib.models.DIPLS.predict" title="Link to this definition"></a></dt>
<dd><p>Predict y using the fitted DIPLS model.</p>
<p>This method predicts the response variable for the provided test data using
the fitted domain-invariant partial least squares (di-PLS) model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">ndarray of shape (n_samples, n_features)</span></dt><dd><p>Test data matrix to perform the prediction on.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>yhat</strong><span class="classifier">ndarray of shape (n_samples_test,)</span></dt><dd><p>Predicted response values for the test data.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="diPLSlib.models.DIPLS.set_fit_request">
<span class="sig-name descname"><span class="pre">set_fit_request</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'$UNCHANGED$'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'$UNCHANGED$'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#diPLSlib.models.DIPLS" title="diPLSlib.models.DIPLS"><span class="pre">DIPLS</span></a></span></span><a class="headerlink" href="#diPLSlib.models.DIPLS.set_fit_request" title="Link to this definition"></a></dt>
<dd><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method.</p>
<p>Note that this method is only relevant if
<code class="docutils literal notranslate"><span class="pre">enable_metadata_routing=True</span></code> (see <code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.set_config()</span></code>).
Please see <span class="xref std std-ref">User Guide</span> on how the routing
mechanism works.</p>
<p>The options for each parameter are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">True</span></code>: metadata is requested, and passed to <code class="docutils literal notranslate"><span class="pre">fit</span></code> if provided. The request is ignored if metadata is not provided.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">False</span></code>: metadata is not requested and the meta-estimator will not pass it to <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code>: metadata is not requested, and the meta-estimator will raise an error if the user provides it.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">str</span></code>: metadata should be passed to the meta-estimator with this given alias instead of the original name.</p></li>
</ul>
<p>The default (<code class="docutils literal notranslate"><span class="pre">sklearn.utils.metadata_routing.UNCHANGED</span></code>) retains the
existing request. This allows you to change the request for some
parameters and not others.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.3.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is only relevant if this estimator is used as a
sub-estimator of a meta-estimator, e.g. used inside a
<code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>. Otherwise it has no effect.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>xs</strong><span class="classifier">str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED</span></dt><dd><p>Metadata routing for <code class="docutils literal notranslate"><span class="pre">xs</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p>
</dd>
<dt><strong>xt</strong><span class="classifier">str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED</span></dt><dd><p>Metadata routing for <code class="docutils literal notranslate"><span class="pre">xt</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>The updated object.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="diPLSlib.models.DIPLS.set_score_request">
<span class="sig-name descname"><span class="pre">set_score_request</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'$UNCHANGED$'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#diPLSlib.models.DIPLS" title="diPLSlib.models.DIPLS"><span class="pre">DIPLS</span></a></span></span><a class="headerlink" href="#diPLSlib.models.DIPLS.set_score_request" title="Link to this definition"></a></dt>
<dd><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">score</span></code> method.</p>
<p>Note that this method is only relevant if
<code class="docutils literal notranslate"><span class="pre">enable_metadata_routing=True</span></code> (see <code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.set_config()</span></code>).
Please see <span class="xref std std-ref">User Guide</span> on how the routing
mechanism works.</p>
<p>The options for each parameter are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">True</span></code>: metadata is requested, and passed to <code class="docutils literal notranslate"><span class="pre">score</span></code> if provided. The request is ignored if metadata is not provided.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">False</span></code>: metadata is not requested and the meta-estimator will not pass it to <code class="docutils literal notranslate"><span class="pre">score</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code>: metadata is not requested, and the meta-estimator will raise an error if the user provides it.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">str</span></code>: metadata should be passed to the meta-estimator with this given alias instead of the original name.</p></li>
</ul>
<p>The default (<code class="docutils literal notranslate"><span class="pre">sklearn.utils.metadata_routing.UNCHANGED</span></code>) retains the
existing request. This allows you to change the request for some
parameters and not others.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.3.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is only relevant if this estimator is used as a
sub-estimator of a meta-estimator, e.g. used inside a
<code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>. Otherwise it has no effect.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>sample_weight</strong><span class="classifier">str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED</span></dt><dd><p>Metadata routing for <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">score</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>The updated object.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="diPLSlib.models.EDPLS">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">diPLSlib.models.</span></span><span class="sig-name descname"><span class="pre">EDPLS</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">centering</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/diPLSlib/models.html#EDPLS"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#diPLSlib.models.EDPLS" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#diPLSlib.models.DIPLS" title="diPLSlib.models.DIPLS"><code class="xref py py-class docutils literal notranslate"><span class="pre">DIPLS</span></code></a></p>
<p><span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-Differentially Private Partial Least Squares Regression.</p>
<p>This class implements the  <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-Differentially Private Partial Least Squares (PLS) regression method by Nikzad-Langerodi et al. (2024, unpublished).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>A: int</strong></dt><dd><p>Number of latent variables.</p>
</dd>
<dt><strong>epsilon</strong><span class="classifier">float</span></dt><dd><p>Privacy loss parameter.</p>
</dd>
<dt><strong>delta</strong><span class="classifier">float, default=0.05</span></dt><dd><p>Failure probability.</p>
</dd>
<dt><strong>centering</strong><span class="classifier">bool, default=True</span></dt><dd><p>If True, the data will be centered before fitting the model.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>n_: int</strong></dt><dd><p>Number of samples in the training data.</p>
</dd>
<dt><strong>n_features_: int</strong></dt><dd><p>Number of features in the training data.</p>
</dd>
<dt><strong>x_mean_: array, shape (n_features,)</strong></dt><dd><p>Estimated mean of each feature.</p>
</dd>
<dt><strong>coef_: array, shape (n_features,)</strong></dt><dd><p>Estimated regression coefficients.</p>
</dd>
<dt><strong>y_mean_: float</strong></dt><dd><p>Estimated intercept.</p>
</dd>
<dt><strong>x_scores_: array, shape (n, A)</strong></dt><dd><p>X scores.</p>
</dd>
<dt><strong>x_loadings_: array, shape (n_features, A)</strong></dt><dd><p>X loadings.</p>
</dd>
<dt><strong>x_weights_: array, shape (n_features, A)</strong></dt><dd><p>X weights.</p>
</dd>
<dt><strong>y_loadings_: array, shape (n_features, A)</strong></dt><dd><p>Y loadings.</p>
</dd>
<dt><strong>is_fitted_: bool</strong></dt><dd><p>True if the model has been fitted.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#diPLSlib.models.EDPLS.fit" title="diPLSlib.models.EDPLS.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(X, y)</p></td>
<td><p>Fit the EDPLS model.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_metadata_routing</span></code>()</p></td>
<td><p>Get metadata routing of this object.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#diPLSlib.models.EDPLS.predict" title="diPLSlib.models.EDPLS.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(x)</p></td>
<td><p>Predict y using the fitted EDPLS model.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">score</span></code>(X, y[, sample_weight])</p></td>
<td><p>Return the coefficient of determination of the prediction.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_fit_request</span></code>(*[, xs, xt])</p></td>
<td><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#diPLSlib.models.EDPLS.set_predict_request" title="diPLSlib.models.EDPLS.set_predict_request"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_predict_request</span></code></a>(*[, x])</p></td>
<td><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">predict</span></code> method.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#diPLSlib.models.EDPLS.set_score_request" title="diPLSlib.models.EDPLS.set_score_request"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_score_request</span></code></a>(*[, sample_weight])</p></td>
<td><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">score</span></code> method.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<ul class="simple">
<li><p>R.Nikzad-Langerodi, et al. (2024). (epsilon,delta)-Differentially private partial least squares regression (2024, unpublished).</p></li>
<li><p>Balle, B., &amp; Wang, Y. X. (2018, July). Improving the gaussian mechanism for differential privacy: Analytical calibration and optimal denoising. In International Conference on Machine Learning (pp. 394-403). PMLR.</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">diPLSlib.models</span> <span class="kn">import</span> <span class="n">EDPLS</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">EDPLS</span><span class="p">(</span><span class="n">A</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">EDPLS(A=5, delta=0.01, epsilon=0.1)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xtest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">yhat</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xtest</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="diPLSlib.models.EDPLS.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/diPLSlib/models.html#EDPLS.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#diPLSlib.models.EDPLS.fit" title="Link to this definition"></a></dt>
<dd><p>Fit the EDPLS model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array, shape (n_samples, n_features)</span></dt><dd><p>Training data.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array, shape (n_samples,)</span></dt><dd><p>Target values.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>Fitted model instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="diPLSlib.models.EDPLS.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/diPLSlib/models.html#EDPLS.predict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#diPLSlib.models.EDPLS.predict" title="Link to this definition"></a></dt>
<dd><p>Predict y using the fitted EDPLS model.</p>
<p>Parameters</p>
<hr class="docutils" />
<dl class="simple">
<dt>x: numpy array of shape (n_samples_test, n_features)</dt><dd><p>Test data matrix to perform the prediction on.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>yhat: numpy array of shape (n_samples_test, )</dt><dd><p>Predicted response values for the test data.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="diPLSlib.models.EDPLS.set_predict_request">
<span class="sig-name descname"><span class="pre">set_predict_request</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'$UNCHANGED$'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#diPLSlib.models.EDPLS" title="diPLSlib.models.EDPLS"><span class="pre">EDPLS</span></a></span></span><a class="headerlink" href="#diPLSlib.models.EDPLS.set_predict_request" title="Link to this definition"></a></dt>
<dd><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">predict</span></code> method.</p>
<p>Note that this method is only relevant if
<code class="docutils literal notranslate"><span class="pre">enable_metadata_routing=True</span></code> (see <code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.set_config()</span></code>).
Please see <span class="xref std std-ref">User Guide</span> on how the routing
mechanism works.</p>
<p>The options for each parameter are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">True</span></code>: metadata is requested, and passed to <code class="docutils literal notranslate"><span class="pre">predict</span></code> if provided. The request is ignored if metadata is not provided.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">False</span></code>: metadata is not requested and the meta-estimator will not pass it to <code class="docutils literal notranslate"><span class="pre">predict</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code>: metadata is not requested, and the meta-estimator will raise an error if the user provides it.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">str</span></code>: metadata should be passed to the meta-estimator with this given alias instead of the original name.</p></li>
</ul>
<p>The default (<code class="docutils literal notranslate"><span class="pre">sklearn.utils.metadata_routing.UNCHANGED</span></code>) retains the
existing request. This allows you to change the request for some
parameters and not others.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.3.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is only relevant if this estimator is used as a
sub-estimator of a meta-estimator, e.g. used inside a
<code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>. Otherwise it has no effect.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED</span></dt><dd><p>Metadata routing for <code class="docutils literal notranslate"><span class="pre">x</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">predict</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>The updated object.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="diPLSlib.models.EDPLS.set_score_request">
<span class="sig-name descname"><span class="pre">set_score_request</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'$UNCHANGED$'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#diPLSlib.models.EDPLS" title="diPLSlib.models.EDPLS"><span class="pre">EDPLS</span></a></span></span><a class="headerlink" href="#diPLSlib.models.EDPLS.set_score_request" title="Link to this definition"></a></dt>
<dd><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">score</span></code> method.</p>
<p>Note that this method is only relevant if
<code class="docutils literal notranslate"><span class="pre">enable_metadata_routing=True</span></code> (see <code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.set_config()</span></code>).
Please see <span class="xref std std-ref">User Guide</span> on how the routing
mechanism works.</p>
<p>The options for each parameter are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">True</span></code>: metadata is requested, and passed to <code class="docutils literal notranslate"><span class="pre">score</span></code> if provided. The request is ignored if metadata is not provided.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">False</span></code>: metadata is not requested and the meta-estimator will not pass it to <code class="docutils literal notranslate"><span class="pre">score</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code>: metadata is not requested, and the meta-estimator will raise an error if the user provides it.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">str</span></code>: metadata should be passed to the meta-estimator with this given alias instead of the original name.</p></li>
</ul>
<p>The default (<code class="docutils literal notranslate"><span class="pre">sklearn.utils.metadata_routing.UNCHANGED</span></code>) retains the
existing request. This allows you to change the request for some
parameters and not others.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.3.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is only relevant if this estimator is used as a
sub-estimator of a meta-estimator, e.g. used inside a
<code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>. Otherwise it has no effect.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>sample_weight</strong><span class="classifier">str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED</span></dt><dd><p>Metadata routing for <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">score</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>The updated object.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="diPLSlib.models.GCTPLS">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">diPLSlib.models.</span></span><span class="sig-name descname"><span class="pre">GCTPLS</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">centering</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">heuristic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rescale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Target'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/diPLSlib/models.html#GCTPLS"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#diPLSlib.models.GCTPLS" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#diPLSlib.models.DIPLS" title="diPLSlib.models.DIPLS"><code class="xref py py-class docutils literal notranslate"><span class="pre">DIPLS</span></code></a></p>
<p>Graph-based Calibration Transfer Partial Least Squares (GCT-PLS).</p>
<p>This method minimizes the distance betwee source (xs) and target (xt) domain data pairs in the latent variable space
while fitting the response.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>l</strong><span class="classifier">float or tuple with len(l)=A, default=0</span></dt><dd><p>Regularization parameter. If a single value is provided, the same regularization is applied to all latent variables.</p>
</dd>
<dt><strong>centering</strong><span class="classifier">bool, default=True</span></dt><dd><p>If True, source and target domain data are mean-centered before fitting.
Centering can be crucial in adjusting data for more effective transfer learning.</p>
</dd>
<dt><strong>heuristic</strong><span class="classifier">bool, default=False</span></dt><dd><p>If True, the regularization parameter is set to a heuristic value aimed
at balancing model fitting quality for the response variable y while minimizing
discrepancies between domain representations.</p>
</dd>
<dt><strong>rescale</strong><span class="classifier">Union[str, ndarray], default=’Target’</span></dt><dd><p>Determines rescaling of the test data. If ‘Target’ or ‘Source’, the test data will be rescaled to the mean of xt or xs, respectively. 
If an ndarray is provided, the test data will be rescaled to the mean of the provided array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>n_</strong><span class="classifier">int</span></dt><dd><p>Number of samples in <cite>x</cite>.</p>
</dd>
<dt><strong>ns_</strong><span class="classifier">int</span></dt><dd><p>Number of samples in <cite>xs</cite>.</p>
</dd>
<dt><strong>nt_</strong><span class="classifier">int</span></dt><dd><p>Number of samples in <cite>xt</cite>.</p>
</dd>
<dt><strong>n_features_in_</strong><span class="classifier">int</span></dt><dd><p>Number of features (variables) in <cite>x</cite>.</p>
</dd>
<dt><strong>mu_</strong><span class="classifier">ndarray of shape (n_features,)</span></dt><dd><p>Mean of columns in <cite>x</cite>.</p>
</dd>
<dt><strong>mu_s_</strong><span class="classifier">ndarray of shape (n_features,)</span></dt><dd><p>Mean of columns in <cite>xs</cite>.</p>
</dd>
<dt><strong>mu_t_</strong><span class="classifier">ndarray of shape (n_features,)</span></dt><dd><p>Mean of columns in <cite>xt</cite>.</p>
</dd>
<dt><strong>b_</strong><span class="classifier">ndarray of shape (n_features, 1)</span></dt><dd><p>Regression coefficient vector.</p>
</dd>
<dt><strong>b0_</strong><span class="classifier">float</span></dt><dd><p>Intercept of the regression model.</p>
</dd>
<dt><strong>T_</strong><span class="classifier">ndarray of shape (n_samples, A)</span></dt><dd><p>Training data projections (scores).</p>
</dd>
<dt><strong>Ts_</strong><span class="classifier">ndarray of shape (n_source_samples, A)</span></dt><dd><p>Source domain projections (scores).</p>
</dd>
<dt><strong>Tt_</strong><span class="classifier">ndarray of shape (n_target_samples, A)</span></dt><dd><p>Target domain projections (scores).</p>
</dd>
<dt><strong>W_</strong><span class="classifier">ndarray of shape (n_features, A)</span></dt><dd><p>Weight matrix.</p>
</dd>
<dt><strong>P_</strong><span class="classifier">ndarray of shape (n_features, A)</span></dt><dd><p>Loadings matrix corresponding to x.</p>
</dd>
<dt><strong>Ps_</strong><span class="classifier">ndarray of shape (n_features, A)</span></dt><dd><p>Loadings matrix corresponding to xs.</p>
</dd>
<dt><strong>Pt_</strong><span class="classifier">ndarray of shape (n_features, A)</span></dt><dd><p>Loadings matrix corresponding to xt.</p>
</dd>
<dt><strong>E_</strong><span class="classifier">ndarray of shape (n_source_samples, n_features)</span></dt><dd><p>Residuals of source domain data.</p>
</dd>
<dt><strong>Es_</strong><span class="classifier">ndarray of shape (n_source_samples, n_features)</span></dt><dd><p>Source domain residual matrix.</p>
</dd>
<dt><strong>Et_</strong><span class="classifier">ndarray of shape (n_target_samples, n_features)</span></dt><dd><p>Target domain residual matrix.</p>
</dd>
<dt><strong>Ey_</strong><span class="classifier">ndarray of shape (n_source_samples, 1)</span></dt><dd><p>Residuals of response variable in the source domain.</p>
</dd>
<dt><strong>C_</strong><span class="classifier">ndarray of shape (A, 1)</span></dt><dd><p>Regression vector relating source projections to the response variable.</p>
</dd>
<dt><strong>opt_l_</strong><span class="classifier">ndarray of shape (A, 1)</span></dt><dd><p>Heuristically determined regularization parameter for each latent variable.</p>
</dd>
<dt><strong>discrepancy_</strong><span class="classifier">ndarray</span></dt><dd><p>The variance discrepancy between source and target domain projections.</p>
</dd>
<dt><strong>is_fitted_</strong><span class="classifier">bool, default=False</span></dt><dd><p>Whether the model has been fitted to data.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#diPLSlib.models.GCTPLS.fit" title="diPLSlib.models.GCTPLS.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(X, y[, xs, xt])</p></td>
<td><p>Fit the GCT-PLS model to data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_metadata_routing</span></code>()</p></td>
<td><p>Get metadata routing of this object.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code>(X)</p></td>
<td><p>Predict y using the fitted DIPLS model.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">score</span></code>(X, y[, sample_weight])</p></td>
<td><p>Return the coefficient of determination of the prediction.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#diPLSlib.models.GCTPLS.set_fit_request" title="diPLSlib.models.GCTPLS.set_fit_request"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_fit_request</span></code></a>(*[, xs, xt])</p></td>
<td><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#diPLSlib.models.GCTPLS.set_score_request" title="diPLSlib.models.GCTPLS.set_score_request"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_score_request</span></code></a>(*[, sample_weight])</p></td>
<td><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">score</span></code> method.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<p>Nikzad‐Langerodi, R., &amp; Sobieczky, F. (2021). Graph‐based calibration transfer. 
Journal of Chemometrics, 35(4), e3319.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">diPLSlib.models</span> <span class="kn">import</span> <span class="n">GCTPLS</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">GCTPLS</span><span class="p">(</span><span class="n">A</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">l</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span>
<span class="go">GCTPLS(A=3, l=(2, 5, 7))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xtest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">yhat</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xtest</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="diPLSlib.models.GCTPLS.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/diPLSlib/models.html#GCTPLS.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#diPLSlib.models.GCTPLS.fit" title="Link to this definition"></a></dt>
<dd><p>Fit the GCT-PLS model to data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">ndarray of shape (n_samples, n_features)</span></dt><dd><p>Labeled input data from the source domain.</p>
</dd>
<dt><strong>y</strong><span class="classifier">ndarray of shape (n_samples, 1)</span></dt><dd><p>Response variable corresponding to the input data <cite>x</cite>.</p>
</dd>
<dt><strong>xs</strong><span class="classifier">ndarray of shape (n_sample_pairs, n_features)</span></dt><dd><p>Source domain X-data. If not provided, defaults to <cite>X</cite>.</p>
</dd>
<dt><strong>xt</strong><span class="classifier">ndarray of shape (n_sample_pairs, n_features)</span></dt><dd><p>Target domain X-data. If not provided, defaults to <cite>X</cite>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>Fitted model instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="diPLSlib.models.GCTPLS.set_fit_request">
<span class="sig-name descname"><span class="pre">set_fit_request</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'$UNCHANGED$'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'$UNCHANGED$'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#diPLSlib.models.GCTPLS" title="diPLSlib.models.GCTPLS"><span class="pre">GCTPLS</span></a></span></span><a class="headerlink" href="#diPLSlib.models.GCTPLS.set_fit_request" title="Link to this definition"></a></dt>
<dd><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method.</p>
<p>Note that this method is only relevant if
<code class="docutils literal notranslate"><span class="pre">enable_metadata_routing=True</span></code> (see <code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.set_config()</span></code>).
Please see <span class="xref std std-ref">User Guide</span> on how the routing
mechanism works.</p>
<p>The options for each parameter are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">True</span></code>: metadata is requested, and passed to <code class="docutils literal notranslate"><span class="pre">fit</span></code> if provided. The request is ignored if metadata is not provided.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">False</span></code>: metadata is not requested and the meta-estimator will not pass it to <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code>: metadata is not requested, and the meta-estimator will raise an error if the user provides it.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">str</span></code>: metadata should be passed to the meta-estimator with this given alias instead of the original name.</p></li>
</ul>
<p>The default (<code class="docutils literal notranslate"><span class="pre">sklearn.utils.metadata_routing.UNCHANGED</span></code>) retains the
existing request. This allows you to change the request for some
parameters and not others.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.3.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is only relevant if this estimator is used as a
sub-estimator of a meta-estimator, e.g. used inside a
<code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>. Otherwise it has no effect.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>xs</strong><span class="classifier">str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED</span></dt><dd><p>Metadata routing for <code class="docutils literal notranslate"><span class="pre">xs</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p>
</dd>
<dt><strong>xt</strong><span class="classifier">str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED</span></dt><dd><p>Metadata routing for <code class="docutils literal notranslate"><span class="pre">xt</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>The updated object.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="diPLSlib.models.GCTPLS.set_score_request">
<span class="sig-name descname"><span class="pre">set_score_request</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'$UNCHANGED$'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#diPLSlib.models.GCTPLS" title="diPLSlib.models.GCTPLS"><span class="pre">GCTPLS</span></a></span></span><a class="headerlink" href="#diPLSlib.models.GCTPLS.set_score_request" title="Link to this definition"></a></dt>
<dd><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">score</span></code> method.</p>
<p>Note that this method is only relevant if
<code class="docutils literal notranslate"><span class="pre">enable_metadata_routing=True</span></code> (see <code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.set_config()</span></code>).
Please see <span class="xref std std-ref">User Guide</span> on how the routing
mechanism works.</p>
<p>The options for each parameter are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">True</span></code>: metadata is requested, and passed to <code class="docutils literal notranslate"><span class="pre">score</span></code> if provided. The request is ignored if metadata is not provided.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">False</span></code>: metadata is not requested and the meta-estimator will not pass it to <code class="docutils literal notranslate"><span class="pre">score</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code>: metadata is not requested, and the meta-estimator will raise an error if the user provides it.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">str</span></code>: metadata should be passed to the meta-estimator with this given alias instead of the original name.</p></li>
</ul>
<p>The default (<code class="docutils literal notranslate"><span class="pre">sklearn.utils.metadata_routing.UNCHANGED</span></code>) retains the
existing request. This allows you to change the request for some
parameters and not others.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.3.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is only relevant if this estimator is used as a
sub-estimator of a meta-estimator, e.g. used inside a
<code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>. Otherwise it has no effect.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>sample_weight</strong><span class="classifier">str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED</span></dt><dd><p>Metadata routing for <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">score</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">object</span></dt><dd><p>The updated object.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="diplslib-utils-subpackage">
<h2>diPLSlib.utils subpackage<a class="headerlink" href="#diplslib-utils-subpackage" title="Link to this heading"></a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="diPLSlib.utils.html">diPLSlib.utils subpackage</a><ul>
<li class="toctree-l2"><a class="reference internal" href="diPLSlib.utils.html#module-diPLSlib.utils.misc">diPLSlib.utils.misc module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="diPLSlib.utils.html#diPLSlib.utils.misc.calibrateAnalyticGaussianMechanism"><code class="docutils literal notranslate"><span class="pre">calibrateAnalyticGaussianMechanism()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="diPLSlib.utils.html#diPLSlib.utils.misc.gengaus"><code class="docutils literal notranslate"><span class="pre">gengaus()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="diPLSlib.utils.html#diPLSlib.utils.misc.hellipse"><code class="docutils literal notranslate"><span class="pre">hellipse()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="diPLSlib.utils.html#diPLSlib.utils.misc.rmse"><code class="docutils literal notranslate"><span class="pre">rmse()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="diPLSlib.utils.html#module-diPLSlib.utils">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="module-diPLSlib">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-diPLSlib" title="Link to this heading"></a></h2>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="diPLSlib documentation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="diPLSlib.utils.html" class="btn btn-neutral float-right" title="diPLSlib.utils subpackage" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Ramin Nikzad-Langerodi.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>